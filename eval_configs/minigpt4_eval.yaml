model:
  arch: mini_gpt4_adapter
  model_type: pretrain_vicuna
  freeze_vit: True
  freeze_qformer: True
  max_txt_len: 160
  end_sym: "###"
  low_resource: False
  prompt_path: "prompts/instruct.txt"
  prompt_template: '###Human: {} ###Assistant: '
  ckpt: /mnt/default/users/v-changma1/training_output/minigpt4_stage2_sft_8_tasks/20230721052/checkpoint_19.pth
  # ckpt: /mnt/default/users/v-changma1/ProteinBlip/minigpt4/output/minigpt4_stage2_finetune/20230630034/checkpoint_24.pth
  # ckpt: /mnt/default/users/v-changma1/training_output/minigpt4_stage1_pretrain_align_prompt/20230628144/checkpoint_15.pth


datasets:
  pdb:
    text_processor:
        train:
          name: "blip_caption"
    vis_processor:
        train:
          name: "blip2_1d_protein_train"
          protein_length: 1000
        eval:
          name: "blip2_1d_protein_eval"
          protein_length: 1000
    sample_ratio: 1

  swissprot: 
    text_processor:
        train:
          name: "blip_caption"
    vis_processor:
        train:
          name: "blip2_1d_protein_train"
          protein_length: 1000
        eval:
          name: "blip2_1d_protein_eval"
          protein_length: 10000
    sample_ratio: 1

run:
  task: image_text_pretrain
